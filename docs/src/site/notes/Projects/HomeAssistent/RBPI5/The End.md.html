<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>The End</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
<p>Aktuellen Ausgangslage für das Home Assistant Sprachassistenten-Setup
auf dem Raspberry Pi 5:</p>
<h2 id="laufende-container">Laufende Container</h2>
<ol type="1">
<li><p><strong>Home Assistant</strong></p>
<ul>
<li>Container: <code>homeassistant</code></li>
<li>Status: Läuft seit 30 Stunden</li>
<li>Funktion: Zentrale Smart Home Steuerung</li>
</ul></li>
<li><p><strong>Spracherkennungs-Services (Speech-to-Text)</strong></p>
<ul>
<li>Container: <code>vosk-de</code> und <code>vosk-en</code></li>
<li>Ports: 10300 (Deutsch) und 10301 (Englisch)</li>
<li>Status: Laufen seit 30 Stunden</li>
<li>Funktion: Spracherkennung für Deutsch und Englisch</li>
</ul></li>
<li><p><strong>Wakeword-Erkennung</strong></p>
<ul>
<li>Container: <code>sira-wake</code></li>
<li>Port: 10400</li>
<li>Status: Läuft seit 30 Stunden</li>
<li>Funktion: Erkennung des Aktivierungsworts “Sira”</li>
</ul></li>
<li><p><strong>TTS-Services (Text-to-Speech)</strong></p>
<ul>
<li>Container: <code>csm-lite</code> (vereinfachte Version des
CSM-Modells)</li>
<li>Port: 8000</li>
<li>Status: Läuft seit 30 Stunden</li>
<li>Funktion: Text-zu-Sprache Umwandlung (aktuell mit espeak-ng)</li>
<li>Container: <code>piper-tts</code> (Alternative TTS-Engine)</li>
<li>Port: 10200</li>
<li>Status: Läuft seit 30 Stunden</li>
<li>Funktion: Hochwertigere Text-zu-Sprache Umwandlung</li>
</ul></li>
<li><p><strong>Adapter und Integration</strong></p>
<ul>
<li>Container: <code>simple-adapter</code></li>
<li>Port: 10700</li>
<li>Status: Läuft seit 30 Stunden</li>
<li>Funktion: Vermittelt zwischen CSM-Lite und anderen Diensten</li>
<li>Container: <code>satellite-service</code></li>
<li>Port: 10500</li>
<li>Status: Läuft seit 30 Stunden</li>
<li>Funktion: Koordiniert Wakeword, STT und TTS als Komplettlösung</li>
</ul></li>
<li><p><strong>Build-System</strong></p>
<ul>
<li>Container: <code>buildx_buildkit_charming_swirles0</code></li>
<li>Status: Läuft seit 35 Stunden</li>
<li>Funktion: Docker-Build-Tool</li>
</ul></li>
</ol>
<h2 id="herausforderungen">Herausforderungen</h2>
<p>Die Hauptherausforderung war die Integration des CSM-Modells
(Conversational Speech Model) von Sesame Labs, das hochqualitative
Sprachausgabe ermöglichen würde. Die Probleme waren:</p>
<ol type="1">
<li><p><strong>Ressourcenbeschränkungen</strong>: Das CSM-Modell mit
seinen 1B Parametern ist zu rechenintensiv für ein effizientes Laufen
auf dem Raspberry Pi 5.</p></li>
<li><p><strong>Abhängigkeitsprobleme</strong>: Die Installation der
erforderlichen Python-Bibliotheken (insbesondere
<code>bitsandbytes</code>) auf ARM-Prozessoren stellte sich als
problematisch heraus.</p></li>
<li><p><strong>Audio-Integration</strong>: Die Audioausgabe über den
Jabra-Lautsprecher innerhalb der Docker-Container erwies sich als
herausfordernd.</p></li>
</ol>
<h2 id="nächste-schritte">Nächste Schritte</h2>
<p>Der Plan, einen leistungsstärkeren Server aufzubauen, ist definitiv
der richtige Weg, um das CSM-Modell mit seiner beeindruckenden
Sprachqualität zu nutzen. Auf einem leistungsstärkeren System könnte
man:</p>
<ol type="1">
<li>Das vollständige CSM-Modell direkt installieren</li>
<li>Schnellere Inferenz-Zeiten erreichen</li>
<li>Die hochwertige weibliche Stimme nutzen, die du dir wünschst</li>
<li>LocalAI als Schnittstelle verwenden, wie im letzten Vorschlag
beschrieben</li>
</ol>
<p>Mit der jetzigen Konfiguration hatte ich bereits eine solide
Grundlage, die ich auf den neuen Server übertragen und dort erweitern
kann. Der Aufbau eines dedizierten Servers für Sprachmodelle ist eine
ausgezeichnete Investition für ein hochwertiges Smart-Home-System.</p>
</body>
</html>
